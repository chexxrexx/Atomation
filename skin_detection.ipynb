{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "11/11 [==============================] - 12s 802ms/step - loss: 2.5054 - accuracy: 0.2963 - val_loss: 98.1223 - val_accuracy: 0.2386\n",
      "Epoch 2/40\n",
      "11/11 [==============================] - 3s 290ms/step - loss: 1.3564 - accuracy: 0.3305 - val_loss: 70.9601 - val_accuracy: 0.2386\n",
      "Epoch 3/40\n",
      "11/11 [==============================] - 3s 242ms/step - loss: 1.3356 - accuracy: 0.3333 - val_loss: 85.0807 - val_accuracy: 0.2841\n",
      "Epoch 4/40\n",
      "11/11 [==============================] - 4s 339ms/step - loss: 1.3394 - accuracy: 0.3390 - val_loss: 116.0930 - val_accuracy: 0.2727\n",
      "Epoch 5/40\n",
      "11/11 [==============================] - 3s 245ms/step - loss: 1.3066 - accuracy: 0.3590 - val_loss: 114.0874 - val_accuracy: 0.2841\n",
      "Epoch 6/40\n",
      "11/11 [==============================] - 3s 286ms/step - loss: 1.2934 - accuracy: 0.3704 - val_loss: 114.9670 - val_accuracy: 0.2727\n",
      "Epoch 7/40\n",
      "11/11 [==============================] - 3s 265ms/step - loss: 1.2859 - accuracy: 0.3618 - val_loss: 117.0703 - val_accuracy: 0.2500\n",
      "Epoch 8/40\n",
      "11/11 [==============================] - 3s 295ms/step - loss: 1.2707 - accuracy: 0.3932 - val_loss: 123.5784 - val_accuracy: 0.2727\n",
      "Epoch 9/40\n",
      "11/11 [==============================] - 4s 344ms/step - loss: 1.2628 - accuracy: 0.3932 - val_loss: 114.5873 - val_accuracy: 0.2727\n",
      "Epoch 10/40\n",
      "11/11 [==============================] - 3s 286ms/step - loss: 1.2399 - accuracy: 0.4131 - val_loss: 146.4369 - val_accuracy: 0.2955\n",
      "Epoch 11/40\n",
      "11/11 [==============================] - 4s 331ms/step - loss: 1.2372 - accuracy: 0.4131 - val_loss: 115.3303 - val_accuracy: 0.2955\n",
      "Epoch 12/40\n",
      "11/11 [==============================] - 4s 337ms/step - loss: 1.2183 - accuracy: 0.4729 - val_loss: 145.6237 - val_accuracy: 0.3182\n",
      "Epoch 13/40\n",
      "11/11 [==============================] - 5s 393ms/step - loss: 1.2270 - accuracy: 0.4217 - val_loss: 159.7523 - val_accuracy: 0.3182\n",
      "Epoch 14/40\n",
      "11/11 [==============================] - 5s 406ms/step - loss: 1.2283 - accuracy: 0.4330 - val_loss: 144.2827 - val_accuracy: 0.3523\n",
      "Epoch 15/40\n",
      "11/11 [==============================] - 6s 353ms/step - loss: 1.1990 - accuracy: 0.4701 - val_loss: 162.6397 - val_accuracy: 0.2955\n",
      "Epoch 16/40\n",
      "11/11 [==============================] - 4s 321ms/step - loss: 1.2113 - accuracy: 0.4387 - val_loss: 242.9103 - val_accuracy: 0.3409\n",
      "Epoch 17/40\n",
      "11/11 [==============================] - 4s 331ms/step - loss: 1.1636 - accuracy: 0.4957 - val_loss: 186.3575 - val_accuracy: 0.2955\n",
      "Epoch 18/40\n",
      "11/11 [==============================] - 4s 305ms/step - loss: 1.1699 - accuracy: 0.5157 - val_loss: 163.4716 - val_accuracy: 0.3068\n",
      "Epoch 19/40\n",
      "11/11 [==============================] - 5s 440ms/step - loss: 1.2088 - accuracy: 0.4017 - val_loss: 251.6654 - val_accuracy: 0.3409\n",
      "Epoch 20/40\n",
      "11/11 [==============================] - 9s 790ms/step - loss: 1.1850 - accuracy: 0.4473 - val_loss: 205.7346 - val_accuracy: 0.2955\n",
      "Epoch 21/40\n",
      "11/11 [==============================] - 5s 321ms/step - loss: 1.1529 - accuracy: 0.4900 - val_loss: 254.8026 - val_accuracy: 0.3636\n",
      "Epoch 22/40\n",
      "11/11 [==============================] - 4s 312ms/step - loss: 1.1337 - accuracy: 0.4786 - val_loss: 244.1735 - val_accuracy: 0.3295\n",
      "Epoch 23/40\n",
      "11/11 [==============================] - 4s 325ms/step - loss: 1.1519 - accuracy: 0.4729 - val_loss: 238.9924 - val_accuracy: 0.3750\n",
      "Epoch 24/40\n",
      "11/11 [==============================] - 3s 287ms/step - loss: 1.1449 - accuracy: 0.4758 - val_loss: 284.2112 - val_accuracy: 0.3750\n",
      "Epoch 25/40\n",
      "11/11 [==============================] - 4s 306ms/step - loss: 1.1265 - accuracy: 0.4957 - val_loss: 355.3603 - val_accuracy: 0.3409\n",
      "Epoch 26/40\n",
      "11/11 [==============================] - 3s 280ms/step - loss: 1.1074 - accuracy: 0.5100 - val_loss: 350.9395 - val_accuracy: 0.3523\n",
      "Epoch 27/40\n",
      "11/11 [==============================] - 3s 266ms/step - loss: 1.1524 - accuracy: 0.4758 - val_loss: 365.0975 - val_accuracy: 0.3523\n",
      "Epoch 28/40\n",
      "11/11 [==============================] - 3s 266ms/step - loss: 1.0919 - accuracy: 0.5185 - val_loss: 344.1284 - val_accuracy: 0.3523\n",
      "Epoch 29/40\n",
      "11/11 [==============================] - 3s 274ms/step - loss: 1.1201 - accuracy: 0.4900 - val_loss: 382.4271 - val_accuracy: 0.3182\n",
      "Epoch 30/40\n",
      "11/11 [==============================] - 3s 279ms/step - loss: 1.1009 - accuracy: 0.5385 - val_loss: 384.5943 - val_accuracy: 0.2386\n",
      "Epoch 31/40\n",
      "11/11 [==============================] - 3s 271ms/step - loss: 1.1058 - accuracy: 0.5128 - val_loss: 385.8745 - val_accuracy: 0.3636\n",
      "Epoch 32/40\n",
      "11/11 [==============================] - 3s 299ms/step - loss: 1.0888 - accuracy: 0.5100 - val_loss: 486.5041 - val_accuracy: 0.3636\n",
      "Epoch 33/40\n",
      "11/11 [==============================] - 3s 291ms/step - loss: 1.1581 - accuracy: 0.4558 - val_loss: 261.3107 - val_accuracy: 0.4091\n",
      "Epoch 34/40\n",
      "11/11 [==============================] - 3s 281ms/step - loss: 1.1111 - accuracy: 0.5071 - val_loss: 412.5757 - val_accuracy: 0.3864\n",
      "Epoch 35/40\n",
      "11/11 [==============================] - 3s 293ms/step - loss: 1.0789 - accuracy: 0.5271 - val_loss: 377.1104 - val_accuracy: 0.3409\n",
      "Epoch 36/40\n",
      "11/11 [==============================] - 3s 259ms/step - loss: 1.1013 - accuracy: 0.5185 - val_loss: 321.6353 - val_accuracy: 0.3523\n",
      "Epoch 37/40\n",
      "11/11 [==============================] - 3s 276ms/step - loss: 1.0504 - accuracy: 0.5185 - val_loss: 438.1565 - val_accuracy: 0.3750\n",
      "Epoch 38/40\n",
      "11/11 [==============================] - 3s 306ms/step - loss: 1.0845 - accuracy: 0.5271 - val_loss: 371.9151 - val_accuracy: 0.3523\n",
      "Epoch 39/40\n",
      "11/11 [==============================] - 3s 292ms/step - loss: 1.0910 - accuracy: 0.5299 - val_loss: 386.5641 - val_accuracy: 0.2955\n",
      "Epoch 40/40\n",
      "11/11 [==============================] - 3s 233ms/step - loss: 1.0736 - accuracy: 0.5356 - val_loss: 466.8887 - val_accuracy: 0.3295\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fe5c5a38f10>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, UpSampling2D, Dense, Flatten # type: ignore\n",
    "from tensorflow.keras.models import Sequential # type: ignore\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from PIL import Image\n",
    "\n",
    "# Constants\n",
    "BD_PATH = \"Dogs/Bacterial_dermatosis\"\n",
    "FI_PATH = \"Dogs/Fungal_infections\"\n",
    "H_PATH = \"Dogs/Healthy\"\n",
    "H_A_D_PATH = \"Dogs/Hypersensitivity_allergic_dermatosis\"\n",
    "EPOCHS = 40\n",
    "IMG_SIZE = (128, 128)  \n",
    "BATCH_SIZE = 32\n",
    "SEED = 12\n",
    "\n",
    "# Random seeds for reproducibility\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "def get_image_paths(folder):\n",
    "    # Return list of paths to images found in specified folder.\n",
    "    if not os.path.exists(folder):\n",
    "        raise FileNotFoundError(f\"The directory {folder} does not exist.\")\n",
    "    return sorted([\n",
    "        Path(folder) / p for p in os.listdir(folder)\n",
    "        if p.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff'))\n",
    "        and not p.startswith('.')\n",
    "    ])\n",
    "\n",
    "def load_and_resize_image(path, size=IMG_SIZE):\n",
    "    # Load image from path and resize it to required size.\n",
    "    try:\n",
    "        img = Image.open(path).convert(\"RGB\")\n",
    "        img = img.resize(size)\n",
    "        return np.array(img)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading image {path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_images_and_labels(paths, label):\n",
    "    # Load images and labels from specified paths.\n",
    "    images = [load_and_resize_image(p) for p in paths]\n",
    "    images = [img for img in images if img is not None]  # Remove failed loads\n",
    "    labels = [label] * len(images)\n",
    "    return images, labels\n",
    "\n",
    "def load_data():\n",
    "    # Load and prepare the dataset.\n",
    "    bds_paths = get_image_paths(BD_PATH)\n",
    "    fi_paths = get_image_paths(FI_PATH)\n",
    "    h_paths = get_image_paths(H_PATH)\n",
    "    h_a_d_paths = get_image_paths(H_A_D_PATH)\n",
    "\n",
    "    bds_images, bds_labels = load_images_and_labels(bds_paths, 0)\n",
    "    fi_images, fi_labels = load_images_and_labels(fi_paths, 1)\n",
    "    h_images, h_labels = load_images_and_labels(h_paths, 2)\n",
    "    h_a_d_images, h_a_d_labels = load_images_and_labels(h_a_d_paths, 3)\n",
    "\n",
    "    images = np.array(bds_images + fi_images + h_images + h_a_d_images)\n",
    "    labels = np.array(bds_labels + fi_labels + h_labels + h_a_d_labels)\n",
    "\n",
    "    return train_test_split(images, labels, test_size=0.2, random_state=SEED, shuffle=True)\n",
    "\n",
    "def create_model():\n",
    "    # CNN Network Model.\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 3)),\n",
    "        MaxPool2D(2, 2),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPool2D(2, 2),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dense(4, activation='softmax')  # 4 classes; change accordingly if we have more classifications\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255, # Normalisation\n",
    "    rotation_range=180, # To capture more different angles\n",
    "    \n",
    "    # 15% Tolerance Range\n",
    "    width_shift_range=0.15,\n",
    "    height_shift_range=0.15,\n",
    "    shear_range=0.15,\n",
    "    zoom_range=0.15,\n",
    "    \n",
    "    # Account for Image Flipping\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    \n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Load and prepare the dataset\n",
    "images_train, images_test, labels_train, labels_test = load_data()\n",
    "model = create_model()\n",
    "\n",
    "# Train the model\n",
    "train_generator = train_datagen.flow(\n",
    "    images_train, labels_train,\n",
    "    batch_size=BATCH_SIZE  # Adjust batch size\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    \n",
    "    # Matching the steps_per_epoch to Batch size to ensure that the \n",
    "    # model is trained on the entire dataset.\n",
    "    steps_per_epoch= np.ceil(len(images_train) / BATCH_SIZE),  \n",
    "    \n",
    "    epochs=EPOCHS,  # Adjust number of epochs\n",
    "    validation_data=(images_test, labels_test)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
